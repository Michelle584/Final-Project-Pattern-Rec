{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06704925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import warnings\n",
    "# importing os module \n",
    "import os\n",
    "# Imports PIL module \n",
    "from keras.models import Model\n",
    "from PIL import Image # for grabbing images\n",
    "from itertools import chain #for target labels \n",
    "from keras.utils import np_utils\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f19dd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf `find -type d -name .ipynb_checkpoints`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a9059a-2542-4a8a-9646-9641a3850857",
   "metadata": {},
   "source": [
    "## Get Training and Test Samples as NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25fa780e-a675-456e-ba39-d6dcd311aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data=False;\n",
    "if save_data==True:\n",
    "    path_of_input_image_classes=\"AID\"\n",
    "    class_names = os.listdir(path_of_input_image_classes) \n",
    "    class_names = [i for i in class_names if i != '.DS_Store'] # Gave me an extraneous class, delete it if it appears\n",
    "    num_of_output_classes=len(class_names);\n",
    "    print('Number of classes in total:\\n')\n",
    "    print(num_of_output_classes);\n",
    "    class_names.sort()\n",
    "    print('\\nTerrain Classes:\\n')\n",
    "    print(class_names)\n",
    "    num_of_images_in_classes = []\n",
    "    all_images = []\n",
    "\n",
    "    for dir in class_names:\n",
    "        filenames = os.listdir(os.path.join(path_of_input_image_classes,dir))\n",
    "        num_of_images_in_classes.append(len(filenames)) # Stores length of each class\n",
    "        for file in filenames:\n",
    "            image = Image.open(os.path.join(path_of_input_image_classes, dir, file))\n",
    "            image = cv2.imread(os.path.join(path_of_input_image_classes, dir, file))\n",
    "            image = cv2.resize(image,(214,214))\n",
    "            all_images.append(image)\n",
    "\n",
    "\n",
    "    Images=np.array(all_images) # this is 10,000 images x pixel num x pixel num x RGB val(3)\n",
    "    print(Images.shape)\n",
    "\n",
    "\n",
    "    # Make target labels\n",
    "    target_labels=[];\n",
    "    class_label=0;\n",
    "    for i in range(num_of_output_classes): # 0 to 29 \n",
    "        num_of_images_current_class=num_of_images_in_classes[i]\n",
    "        append_num=[class_label] * num_of_images_current_class\n",
    "        target_labels.append(append_num)\n",
    "        class_label=class_label+1\n",
    "    target_labels = list(chain.from_iterable(target_labels))\n",
    "    target_labels=np.array(target_labels)\n",
    "\n",
    "\n",
    "    # Split into training and testing \n",
    "    X_train, X_test,t_train, t_test = train_test_split(Images,target_labels,\n",
    "                                       random_state=104, \n",
    "                                       test_size=0.20, \n",
    "                                       shuffle=True)\n",
    "    X_train.shape, X_test.shape, t_train.shape, t_test.shape\n",
    "    \n",
    "    np.save(\"train_data.npy\",X_train)\n",
    "    np.save(\"train_label.npy\",t_train)\n",
    "    np.save(\"test_data.npy\",X_test)\n",
    "    np.save(\"test_labels.npy\",t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00cf8605-8c70-4c78-8e21-b61ce2159cbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train_data.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_data.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m;\n\u001b[1;32m      2\u001b[0m t_train\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_label.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m);\n\u001b[1;32m      3\u001b[0m num_of_output_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(t_train))\n",
      "File \u001b[0;32m/apps/tensorflow/2.7.0/lib/python3.9/site-packages/numpy/lib/npyio.py:407\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    405\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 407\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    408\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_data.npy'"
     ]
    }
   ],
   "source": [
    "X_train=np.load(\"train_data.npy\");\n",
    "t_train=np.load(\"train_label.npy\");\n",
    "num_of_output_classes=len(np.unique(t_train))\n",
    "X_train=tensorflow.keras.applications.vgg16.preprocess_input(\n",
    "    X_train, data_format=None\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d940e25-7ce6-4624-950b-7a2a083e4f8b",
   "metadata": {},
   "source": [
    "## Training on all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580ac747-564c-4591-bc02-f4f7334139a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transfer_learning_CNN(num_of_classes,data_train, labels_train, img_size=214, epochs=5, learning_rate=1e-4):\n",
    "    \n",
    "    # load data and labels\n",
    "    #data_train = np.load(data_train_path)\n",
    "    #labels_train_temp = np.load(labels_train_path)\n",
    "    \n",
    "    # preprocessing\n",
    "    #gray_scaled=Invert_gray_scale(data_train,300) #Converts all 300x300 images to grey scale\n",
    "    \n",
    "    #dilated_data=Dilation(gray_scaled,300) # Dilates all 300x300 images\n",
    "    \n",
    "    #bkg_removed_matrix=Remove_bkg_noise(dilated_data,300) #Removes background from 300x300 images\n",
    "    \n",
    "    #resized_matrix=resize(bkg_removed_matrix,img_size) #Resizes to img_size x img_size\n",
    " \n",
    "    # Normalize data\n",
    "    labels_train = np_utils.to_categorical(labels_train, num_of_classes)\n",
    "    \n",
    "    # specify a new input shape to replace VGG16 input layer for our data\n",
    "    new_input = (img_size, img_size, 3)\n",
    "    \n",
    "    # load model\n",
    "    model = VGG16(include_top=False, input_shape=new_input, pooling='max')\n",
    "    \n",
    "    #remove output layer to replace with new one to allow for classification of the 3 classes instead of the original VGG16\n",
    "    # classification \n",
    "    flat1 = Flatten()(model.layers[-1].output) # remove output layer\n",
    "    class1 = Dense(1024, activation='relu')(flat1) # new dense layer\n",
    "    output = Dense(num_of_classes, activation='softmax')(class1) # for 3 classes\n",
    "    \n",
    "    # define new model\n",
    "    model = Model(inputs=model.inputs, outputs=output)\n",
    "    \n",
    "    # print summary of model\n",
    "    model.summary()\n",
    "\n",
    "    # set Adam learning rate\n",
    "    adam = Adam(lr=learning_rate)\n",
    "\n",
    "    # We add metrics to get more results you want to see\n",
    "    model.compile(optimizer=adam,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # fit model\n",
    "    print('Training ------------')\n",
    "    history = model.fit(X_train,labels_train, epochs=epochs)\n",
    "                \n",
    "    # plot training accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend(['Training'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # save trained VGG16 CNN model\n",
    "    model.save('vgg16_trained_cnn.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f0a56e-0fd6-46c8-b2c4-1b417a966e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train VGG16 CNN\n",
    "train_transfer_learning_CNN(num_of_output_classes,X_train,t_train, img_size=100, epochs=5, learning_rate=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc92419b-6061-45b5-8743-609f861e2492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confusion matrix\n",
    "def conf_matrix_w_acc(y_test, labels):\n",
    "    # Evaluate trained model in validation set\n",
    "    cm = confusion_matrix(y_test, labels)\n",
    "    acc =np.diagonal(cm).sum()/ cm.sum()\n",
    "    # acc = accuracy_score(y_test,labels)\n",
    "    fig, ax = plt.subplots()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    # create heatmap\n",
    "    sns.heatmap(pd.DataFrame(cm), annot=True ,fmt='g', xticklabels = class_names, yticklabels = class_names)\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    plt.tight_layout()\n",
    "    plt.title('Confusion Matrix (Accuracy = %f)' % acc, y=1.1)\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cd71d8-88e3-4c3a-9b8e-c406e71d8a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_w_acc(y_test, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891bfb0e-957d-499e-b9e5-c406a9dd0f76",
   "metadata": {},
   "source": [
    "## Test Performance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef52de68-f453-40c3-b103-fdc8cdb8dd28",
   "metadata": {},
   "source": [
    "accuracy,y_classes=test(num_of_output_classes,X_test,t_test,model_name='vgg16_trained_cnn.hdf5',resized_pixel_size=214)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826744ef-1386-4ef2-8041-82fe059832ba",
   "metadata": {},
   "source": [
    "## Training performance when randomly pulling out 20% of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2527e689-82de-4cf7-bd62-4640d8463284",
   "metadata": {},
   "source": [
    "per_keep=.8 #keep 80% of data\n",
    "X_train_rand=X_train[0:int(per_keep*X_train.shape[0]),:,:,:]\n",
    "t_train_rand=t_train[0:int(per_keep*t_train.shape[0])]\n",
    "print(\"New Training shape\")\n",
    "print(t_train_rand.shape)\n",
    "print(X_train_rand.shape)\n",
    "\n",
    "train_transfer_learning_CNN(num_of_output_classes,X_train_rand,t_train_rand, img_size=214, epochs=5, learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5b4fdb-ba4d-4307-bf92-ff9d718cc86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dfc388-1f8c-40a9-9bc3-ea32dd547ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.7.0",
   "language": "python",
   "name": "tensorflow-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
