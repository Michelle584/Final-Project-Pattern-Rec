{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06704925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import warnings\n",
    "# importing os module \n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "# Imports PIL module \n",
    "from keras.models import Model\n",
    "from PIL import Image # for grabbing images\n",
    "from itertools import chain #for target labels \n",
    "from keras.utils import np_utils\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f19dd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf `find -type d -name .ipynb_checkpoints` #It was automatically creating this file and causing problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a9059a-2542-4a8a-9646-9641a3850857",
   "metadata": {},
   "source": [
    "## Get Training and Test Samples as NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cf8605-8c70-4c78-8e21-b61ce2159cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3360,)\n"
     ]
    }
   ],
   "source": [
    "X_train=np.load(\"train_data.npy\");\n",
    "t_train=np.load(\"train_label.npy\");\n",
    "print(t_train.shape)\n",
    "num_of_output_classes=len(np.unique(t_train))\n",
    "X_train=tensorflow.keras.applications.vgg16.preprocess_input(X_train, data_format=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580ac747-564c-4591-bc02-f4f7334139a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transfer_learning_CNN(num_of_classes,save_file_as,data_train, labels_train, img_size=214, epochs=5, learning_rate=1e-4):\n",
    "    \n",
    "    # load data and labels\n",
    "    #data_train = np.load(data_train_path)\n",
    "    #labels_train_temp = np.load(labels_train_path)\n",
    "    \n",
    "    # preprocessing\n",
    "    #gray_scaled=Invert_gray_scale(data_train,300) #Converts all 300x300 images to grey scale\n",
    "    \n",
    "    #dilated_data=Dilation(gray_scaled,300) # Dilates all 300x300 images\n",
    "    \n",
    "    #bkg_removed_matrix=Remove_bkg_noise(dilated_data,300) #Removes background from 300x300 images\n",
    "    \n",
    "    #resized_matrix=resize(bkg_removed_matrix,img_size) #Resizes to img_size x img_size\n",
    " \n",
    "    # Normalize data\n",
    "    labels_train = np_utils.to_categorical(labels_train, num_of_classes)\n",
    "    \n",
    "    # specify a new input shape to replace VGG16 input layer for our data\n",
    "    new_input = (img_size, img_size, 3)\n",
    "    \n",
    "    # load model\n",
    "    model = VGG16(include_top=False, input_shape=new_input, pooling='max')\n",
    "    \n",
    "    #remove output layer to replace with new one to allow for classification of the 3 classes instead of the original VGG16\n",
    "    # classification \n",
    "    flat1 = Flatten()(model.layers[-1].output) # remove output layer\n",
    "    class1 = Dense(1024, activation='relu')(flat1) # new dense layer\n",
    "    output = Dense(num_of_classes, activation='softmax')(class1) # for 3 classes\n",
    "    \n",
    "    # define new model\n",
    "    model = Model(inputs=model.inputs, outputs=output)\n",
    "    \n",
    "    # print summary of model\n",
    "    model.summary()\n",
    "\n",
    "    # set Adam learning rate\n",
    "    adam = Adam(lr=learning_rate)\n",
    "\n",
    "    # We add metrics to get more results you want to see\n",
    "    model.compile(optimizer=adam,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # fit model\n",
    "    print('Training ------------')\n",
    "    history = model.fit(data_train,labels_train, epochs=epochs)\n",
    "                \n",
    "    # plot training accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend(['Training'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # save trained VGG16 CNN model\n",
    "    model.save(save_file_as)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3e1123-9631-4dc7-b54b-e45058a64948",
   "metadata": {},
   "source": [
    "## Training on all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f0a56e-0fd6-46c8-b2c4-1b417a966e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train VGG16 CNN if there is no file\n",
    "if os.path.isfile('vgg16_trained_cnn.hdf5')==False:\n",
    "    train_transfer_learning_CNN(num_of_output_classes,'vgg16_trained_cnn.hdf5',X_train,t_train, img_size=100, epochs=5, learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826744ef-1386-4ef2-8041-82fe059832ba",
   "metadata": {},
   "source": [
    "## Training performance when randomly pulling out 50% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966a3ba6-fd88-4d1a-b19e-9c9d02740f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('vgg16_rand_pullout_50.hdf5')==False:\n",
    "    per_keep=.5 #keep 50% of data\n",
    "    X_train_rand=X_train[0:int(per_keep*X_train.shape[0]),:,:,:]\n",
    "    t_train_rand=t_train[0:int(per_keep*t_train.shape[0])]\n",
    "    print(\"New Training shape\")\n",
    "    print(t_train_rand.shape)\n",
    "    print(X_train_rand.shape)\n",
    "    train_transfer_learning_CNN(num_of_output_classes,'vgg16_rand_pullout_50.hdf5',X_train_rand,t_train_rand, img_size=100, epochs=5, learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f13290-bb2e-4828-a845-f178720626b4",
   "metadata": {},
   "source": [
    "## Training performance when randomly pulling out 80% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dfc388-1f8c-40a9-9bc3-ea32dd547ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('vgg16_rand_pullout_80.hdf5')==False:\n",
    "    per_keep=.2 #keep 20% of data\n",
    "    X_train_rand=X_train[0:int(per_keep*X_train.shape[0]),:,:,:]\n",
    "    t_train_rand=t_train[0:int(per_keep*t_train.shape[0])]\n",
    "    print(\"New Training shape\")\n",
    "    print(t_train_rand.shape)\n",
    "    print(X_train_rand.shape)\n",
    "\n",
    "    train_transfer_learning_CNN(num_of_output_classes,'vgg16_rand_pullout_80.hdf5',X_train_rand,t_train_rand, img_size=100, epochs=5, learning_rate=1e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.7.0",
   "language": "python",
   "name": "tensorflow-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
